{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chitimbwasc/chitimbwasc/blob/main/Laion_Pipeline_with_Dask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dfc987f-cf25-4cb3-af17-383f84466156",
      "metadata": {
        "id": "4dfc987f-cf25-4cb3-af17-383f84466156"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from dask.distributed import Client\n",
        "from dask import bag, delayed, compute, config\n",
        "from faster_whisper import WhisperModel\n",
        "import torch\n",
        "import json\n",
        "import dask\n",
        "import whisperx\n",
        "import pandas as pd\n",
        "from omegaconf import OmegaConf\n",
        "from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "from pydub import AudioSegment\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "345a0730-f615-4c02-ae05-b5fb06f7bddc",
      "metadata": {
        "id": "345a0730-f615-4c02-ae05-b5fb06f7bddc",
        "outputId": "e4b699c7-e455-43d3-e4c6-b01604252ffe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
              "    <div style=\"margin-left: 48px;\">\n",
              "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
              "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-0db22ce0-57c6-11ee-ac07-000d3a1470d8</p>\n",
              "        <table style=\"width: 100%; text-align: left;\">\n",
              "\n",
              "        <tr>\n",
              "        \n",
              "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
              "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
              "        \n",
              "        </tr>\n",
              "\n",
              "        \n",
              "            <tr>\n",
              "                <td style=\"text-align: left;\">\n",
              "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
              "                </td>\n",
              "                <td style=\"text-align: left;\"></td>\n",
              "            </tr>\n",
              "        \n",
              "\n",
              "        </table>\n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "            <details>\n",
              "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
              "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
              "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
              "    </div>\n",
              "    <div style=\"margin-left: 48px;\">\n",
              "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
              "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">f3f7285f</p>\n",
              "        <table style=\"width: 100%; text-align: left;\">\n",
              "            <tr>\n",
              "                <td style=\"text-align: left;\">\n",
              "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
              "                </td>\n",
              "                <td style=\"text-align: left;\">\n",
              "                    <strong>Workers:</strong> 3\n",
              "                </td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left;\">\n",
              "                    <strong>Total threads:</strong> 6\n",
              "                </td>\n",
              "                <td style=\"text-align: left;\">\n",
              "                    <strong>Total memory:</strong> 110.05 GiB\n",
              "                </td>\n",
              "            </tr>\n",
              "            \n",
              "            <tr>\n",
              "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
              "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
              "</tr>\n",
              "\n",
              "            \n",
              "        </table>\n",
              "\n",
              "        <details>\n",
              "            <summary style=\"margin-bottom: 20px;\">\n",
              "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
              "            </summary>\n",
              "\n",
              "            <div style=\"\">\n",
              "    <div>\n",
              "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
              "        <div style=\"margin-left: 48px;\">\n",
              "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
              "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-8dcd95c4-2560-44a8-8574-6e52eeb3fc0c</p>\n",
              "            <table style=\"width: 100%; text-align: left;\">\n",
              "                <tr>\n",
              "                    <td style=\"text-align: left;\">\n",
              "                        <strong>Comm:</strong> tcp://127.0.0.1:42635\n",
              "                    </td>\n",
              "                    <td style=\"text-align: left;\">\n",
              "                        <strong>Workers:</strong> 3\n",
              "                    </td>\n",
              "                </tr>\n",
              "                <tr>\n",
              "                    <td style=\"text-align: left;\">\n",
              "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
              "                    </td>\n",
              "                    <td style=\"text-align: left;\">\n",
              "                        <strong>Total threads:</strong> 6\n",
              "                    </td>\n",
              "                </tr>\n",
              "                <tr>\n",
              "                    <td style=\"text-align: left;\">\n",
              "                        <strong>Started:</strong> Just now\n",
              "                    </td>\n",
              "                    <td style=\"text-align: left;\">\n",
              "                        <strong>Total memory:</strong> 110.05 GiB\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </table>\n",
              "        </div>\n",
              "    </div>\n",
              "\n",
              "    <details style=\"margin-left: 48px;\">\n",
              "        <summary style=\"margin-bottom: 20px;\">\n",
              "            <h3 style=\"display: inline;\">Workers</h3>\n",
              "        </summary>\n",
              "\n",
              "        \n",
              "        <div style=\"margin-bottom: 20px;\">\n",
              "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
              "            <div style=\"margin-left: 48px;\">\n",
              "            <details>\n",
              "                <summary>\n",
              "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
              "                </summary>\n",
              "                <table style=\"width: 100%; text-align: left;\">\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Comm: </strong> tcp://127.0.0.1:36347\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Total threads: </strong> 2\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:38599/status\" target=\"_blank\">http://127.0.0.1:38599/status</a>\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Memory: </strong> 36.68 GiB\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Nanny: </strong> tcp://127.0.0.1:43473\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\"></td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
              "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-vzjoqflx\n",
              "                        </td>\n",
              "                    </tr>\n",
              "\n",
              "                    \n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>GPU memory: </strong> 15.78 GiB\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    \n",
              "\n",
              "                    \n",
              "\n",
              "                </table>\n",
              "            </details>\n",
              "            </div>\n",
              "        </div>\n",
              "        \n",
              "        <div style=\"margin-bottom: 20px;\">\n",
              "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
              "            <div style=\"margin-left: 48px;\">\n",
              "            <details>\n",
              "                <summary>\n",
              "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
              "                </summary>\n",
              "                <table style=\"width: 100%; text-align: left;\">\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Comm: </strong> tcp://127.0.0.1:41163\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Total threads: </strong> 2\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:38721/status\" target=\"_blank\">http://127.0.0.1:38721/status</a>\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Memory: </strong> 36.68 GiB\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Nanny: </strong> tcp://127.0.0.1:32961\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\"></td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
              "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-a83m_nv5\n",
              "                        </td>\n",
              "                    </tr>\n",
              "\n",
              "                    \n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>GPU memory: </strong> 15.78 GiB\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    \n",
              "\n",
              "                    \n",
              "\n",
              "                </table>\n",
              "            </details>\n",
              "            </div>\n",
              "        </div>\n",
              "        \n",
              "        <div style=\"margin-bottom: 20px;\">\n",
              "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
              "            <div style=\"margin-left: 48px;\">\n",
              "            <details>\n",
              "                <summary>\n",
              "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
              "                </summary>\n",
              "                <table style=\"width: 100%; text-align: left;\">\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Comm: </strong> tcp://127.0.0.1:34883\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Total threads: </strong> 2\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:39957/status\" target=\"_blank\">http://127.0.0.1:39957/status</a>\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Memory: </strong> 36.68 GiB\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>Nanny: </strong> tcp://127.0.0.1:41961\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\"></td>\n",
              "                    </tr>\n",
              "                    <tr>\n",
              "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
              "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-q9207mhl\n",
              "                        </td>\n",
              "                    </tr>\n",
              "\n",
              "                    \n",
              "                    <tr>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
              "                        </td>\n",
              "                        <td style=\"text-align: left;\">\n",
              "                            <strong>GPU memory: </strong> 15.78 GiB\n",
              "                        </td>\n",
              "                    </tr>\n",
              "                    \n",
              "\n",
              "                    \n",
              "\n",
              "                </table>\n",
              "            </details>\n",
              "            </div>\n",
              "        </div>\n",
              "        \n",
              "\n",
              "    </details>\n",
              "</div>\n",
              "\n",
              "        </details>\n",
              "    </div>\n",
              "</div>\n",
              "            </details>\n",
              "        \n",
              "\n",
              "    </div>\n",
              "</div>"
            ],
            "text/plain": [
              "<Client: 'tcp://127.0.0.1:42635' processes=3 threads=6, memory=110.05 GiB>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client = Client()\n",
        "client"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eb689ae-1925-4f54-b175-4bb1018eb801",
      "metadata": {
        "id": "0eb689ae-1925-4f54-b175-4bb1018eb801"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38327c93-b89f-4cf9-827f-23cce0c3198f",
      "metadata": {
        "id": "38327c93-b89f-4cf9-827f-23cce0c3198f"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "OUTPUT_PATH = Path(\"output\")\n",
        "OUTPUT_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "NEMO_DIARIZATION_CONFIG = Path(\"./diar_infer_telephonic.yaml\")\n",
        "\n",
        "WAV2VEC2_LANGUAGES = list(\n",
        "    {\n",
        "        \"en\",\n",
        "        \"fr\",\n",
        "        \"de\",\n",
        "        \"es\",\n",
        "        \"it\",\n",
        "        \"nl\",\n",
        "        \"ja\",\n",
        "        \"zh\",\n",
        "        \"uk\",\n",
        "        \"pt\",\n",
        "        \"ar\",\n",
        "        \"ru\",\n",
        "        \"pl\",\n",
        "        \"hu\",\n",
        "        \"fi\",\n",
        "        \"fa\",\n",
        "        \"el\",\n",
        "        \"tr\",\n",
        "    }\n",
        ")\n",
        "PUNCTUATION_MODEL_LANGUAGES = [\n",
        "    \"en\",\n",
        "    \"fr\",\n",
        "    \"de\",\n",
        "    \"es\",\n",
        "    \"it\",\n",
        "    \"nl\",\n",
        "    \"pt\",\n",
        "    \"bg\",\n",
        "    \"pl\",\n",
        "    \"cs\",\n",
        "    \"sk\",\n",
        "    \"sl\",\n",
        "]\n",
        "SENTENCE_ENDING_PUNCTUATIONS = \".?!\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35783d6c-a7b0-46c1-b0de-a33dc7f9dc9d",
      "metadata": {
        "id": "35783d6c-a7b0-46c1-b0de-a33dc7f9dc9d"
      },
      "source": [
        "### Convert the audios to wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4112bc6-60a0-4443-9a69-7b9651e5f649",
      "metadata": {
        "id": "a4112bc6-60a0-4443-9a69-7b9651e5f649"
      },
      "outputs": [],
      "source": [
        "def convert_audio_to_wav(audio_path: Path, output_path: Path = OUTPUT_PATH) -> Path:\n",
        "    \"\"\"\n",
        "    Convert audio to WAV format using pydub.\n",
        "\n",
        "    Parameters:\n",
        "        audio_path (Path): The path to the input audio file.\n",
        "        output_path (Path): The path to the output directory.\n",
        "\n",
        "    Returns:\n",
        "        Path: The path to the converted WAV file.\n",
        "    \"\"\"\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "    audio = audio.set_channels(1)\n",
        "    output_audio_path = output_path / f\"{audio_path.stem}.wav\"\n",
        "    audio.export(output_audio_path, format=\"wav\")\n",
        "    return output_audio_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57074fbc-7627-490a-b864-e7ae11409700",
      "metadata": {
        "id": "57074fbc-7627-490a-b864-e7ae11409700"
      },
      "outputs": [],
      "source": [
        "audio_dir = Path('./inputs/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fdde5f0-6c3a-4f51-9216-df2d03d6267c",
      "metadata": {
        "id": "3fdde5f0-6c3a-4f51-9216-df2d03d6267c"
      },
      "source": [
        "### Get Whisper Transcription"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28a05d51-15eb-4c8d-a996-ea7d23e4ab0c",
      "metadata": {
        "id": "28a05d51-15eb-4c8d-a996-ea7d23e4ab0c"
      },
      "source": [
        "#### Whisper models\n",
        "\n",
        "| Size   | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "|--------|------------|--------------------|--------------------|---------------|----------------|\n",
        "| tiny   | 39 M       | tiny.en            | tiny               | ~1 GB         | ~32x           |\n",
        "| base   | 74 M       | base.en            | base               | ~1 GB         | ~16x           |\n",
        "| small  | 244 M      | small.en           | small              | ~2 GB         | ~6x            |\n",
        "| medium | 769 M      | medium.en          | medium             | ~5 GB         | ~2x            |\n",
        "| large  | 1550 M     | N/A                | large              | ~10 GB        | 1x             |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6312cfc9-c579-43fa-9be8-e433aa4eaffc",
      "metadata": {
        "id": "6312cfc9-c579-43fa-9be8-e433aa4eaffc"
      },
      "source": [
        "#### Large-v2 model on GPU\n",
        "\n",
        "| Implementation | Precision | Beam size | Time | Max. GPU memory | Max. CPU memory |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| openai/whisper | fp16 | 5 | 4m30s | 11325MB | 9439MB |\n",
        "| faster-whisper | fp16 | 5 | 54s | 4755MB | 3244MB |\n",
        "| faster-whisper | int8 | 5 | 59s | 3091MB | 3117MB |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b6757a-365c-4df5-ba0b-dba4bf2bc658",
      "metadata": {
        "id": "61b6757a-365c-4df5-ba0b-dba4bf2bc658"
      },
      "source": [
        "#### Small model on CPU\n",
        "\n",
        "| Implementation | Precision | Beam size | Time | Max. memory |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| openai/whisper | fp32 | 5 | 10m31s | 3101MB |\n",
        "| whisper.cpp | fp32 | 5 | 17m42s | 1581MB |\n",
        "| whisper.cpp | fp16 | 5 | 12m39s | 873MB |\n",
        "| faster-whisper | fp32 | 5 | 2m44s | 1675MB |\n",
        "| faster-whisper | int8 | 5 | 2m04s | 995MB |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d94050-89e1-4fb7-a2aa-0f0ac5f932a7",
      "metadata": {
        "id": "c1d94050-89e1-4fb7-a2aa-0f0ac5f932a7"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"tiny\"\n",
        "# MODEL_NAME = \"large-v2\"\n",
        "\n",
        "\n",
        "# Initialize the model outside the function\n",
        "whisper_model = None\n",
        "\n",
        "def get_whisper_transcription(\n",
        "    audio_path: Path, model_name=MODEL_NAME, device=\"cuda\", beam_size=5\n",
        "):\n",
        "    global whisper_model\n",
        "    if whisper_model is None:\n",
        "        whisper_model = WhisperModel(model_name, device=device)\n",
        "\n",
        "    segments, info = whisper_model.transcribe(\n",
        "        str(audio_path),\n",
        "        beam_size=beam_size,\n",
        "        word_timestamps=True,\n",
        "    )\n",
        "\n",
        "    return [segment._asdict() for segment in segments], info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f021dc1-d4f3-446e-99c9-155aec9b195c",
      "metadata": {
        "id": "4f021dc1-d4f3-446e-99c9-155aec9b195c"
      },
      "outputs": [],
      "source": [
        "def create_nemo_diarization_config(\n",
        "    audio_path: Path, nemo_config_path: Path, output_path: Path = OUTPUT_PATH\n",
        ") -> OmegaConf:\n",
        "    \"\"\"\n",
        "    Create and configure a NeMo diarization configuration object.\n",
        "    Returns:\n",
        "        OmegaConf: Configuration object for NeMo diarization.\n",
        "    \"\"\"\n",
        "    config = OmegaConf.load(nemo_config_path)\n",
        "\n",
        "    # Prepare data directory and meta-information\n",
        "    data_dir = output_path / \"data\"\n",
        "    data_dir.mkdir(parents=True, exist_ok=True)\n",
        "    meta = {\n",
        "        \"audio_filepath\": str(audio_path),\n",
        "        \"offset\": 0,\n",
        "        \"duration\": None,\n",
        "        \"label\": \"infer\",\n",
        "        \"text\": \"-\",\n",
        "        \"rttm_filepath\": None,\n",
        "        \"uem_filepath\": None,\n",
        "    }\n",
        "\n",
        "    manifest_file_name = f\"{audio_path.stem}_manifest.json\"\n",
        "\n",
        "    # Save meta information\n",
        "    (data_dir / manifest_file_name).write_text(json.dumps(meta) + \"\\n\")\n",
        "\n",
        "    # Pretrained models\n",
        "    pretrained_vad = \"vad_multilingual_marblenet\"\n",
        "    pretrained_speaker_model = \"titanet_large\"\n",
        "\n",
        "    config.num_workers = 1  # Avoid multiprocessing hang with IPython\n",
        "    config.diarizer.manifest_filepath = str(data_dir / manifest_file_name)\n",
        "    config.diarizer.out_dir = str(output_path / audio_path.stem)\n",
        "\n",
        "    config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
        "    config.diarizer.oracle_vad = False  # Use model-based VAD\n",
        "    config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
        "\n",
        "    config.diarizer.vad.model_path = pretrained_vad\n",
        "    config.diarizer.vad.parameters.onset = 0.8\n",
        "    config.diarizer.vad.parameters.offset = 0.6\n",
        "    config.diarizer.vad.parameters.pad_offset = -0.05\n",
        "    config.diarizer.msdd_model.model_path = (\n",
        "        \"diar_msdd_telephonic\"  # Telephonic speaker diarization model\n",
        "    )\n",
        "\n",
        "    return config\n",
        "\n",
        "def get_nemo_diarization(audio_path: Path, nemo_config: OmegaConf):\n",
        "    # Initialize NeMo MSDD diarization model\n",
        "    msdd_model = NeuralDiarizer(cfg=nemo_config, ).to(\"cuda\")\n",
        "    msdd_model.diarize()\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bcedf3a-12e6-48af-9efd-319d18db62b9",
      "metadata": {
        "id": "3bcedf3a-12e6-48af-9efd-319d18db62b9"
      },
      "outputs": [],
      "source": [
        "alignment_model_cache = {}\n",
        "\n",
        "def align_transcription(\n",
        "    audio_path: Path, whisper_results, info, supported_languages=WAV2VEC2_LANGUAGES, device=\"cuda\"\n",
        "):\n",
        "    # Check if language is supported\n",
        "    if info.language not in supported_languages:\n",
        "        return [\n",
        "            {\"text\": word[2], \"start\": word[0], \"end\": word[1]}\n",
        "            for segment in whisper_results\n",
        "            for word in segment[\"words\"]\n",
        "        ]\n",
        "\n",
        "    global alignment_model_cache\n",
        "\n",
        "    # Lazy loading of the alignment model\n",
        "    if info.language not in alignment_model_cache:\n",
        "        alignment_model, metadata = whisperx.load_align_model(\n",
        "            language_code=info.language, device=device\n",
        "        )\n",
        "        alignment_model_cache[info.language] = (alignment_model, metadata)\n",
        "    else:\n",
        "        alignment_model, metadata = alignment_model_cache[info.language]\n",
        "\n",
        "    result_aligned = whisperx.align(\n",
        "        whisper_results, alignment_model, metadata, str(audio_path), device\n",
        "    )\n",
        "\n",
        "    return result_aligned[\"word_segments\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9848f6d-f88f-4af7-ba6c-46707d5fa5b9",
      "metadata": {
        "id": "e9848f6d-f88f-4af7-ba6c-46707d5fa5b9"
      },
      "outputs": [],
      "source": [
        "def get_word_timestamp_anchor(start_time, end_time, option=\"start\"):\n",
        "    \"\"\"\n",
        "    Get the timestamp anchor for a word based on the given option.\n",
        "\n",
        "    Parameters:\n",
        "        start_time (int): The start time of the word in milliseconds.\n",
        "        end_time (int): The end time of the word in milliseconds.\n",
        "        option (str): The option for word timestamp anchor (\"start\", \"mid\", or \"end\").\n",
        "\n",
        "    Returns:\n",
        "        int: The timestamp anchor in milliseconds.\n",
        "    \"\"\"\n",
        "    if option == \"end\":\n",
        "        return end_time\n",
        "    elif option == \"mid\":\n",
        "        return (start_time + end_time) // 2\n",
        "    return start_time\n",
        "\n",
        "\n",
        "@delayed\n",
        "def map_words_to_speaker(\n",
        "    word_timestamps, speaker_timestamps, word_anchor_option=\"start\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Map each word to the corresponding speaker based on timestamps.\n",
        "\n",
        "    Parameters:\n",
        "        word_timestamps (list): A list of dictionaries containing word information.\n",
        "        speaker_timestamps (list): A list of tuples containing speaker information.\n",
        "        word_anchor_option (str): The option for word timestamp anchor (\"start\", \"mid\", or \"end\").\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries containing the mapping of words to speakers.\n",
        "    \"\"\"\n",
        "    speaker_start, speaker_end, speaker = speaker_timestamps[0]\n",
        "    word_speaker_mapping = []\n",
        "    turn_index = 0\n",
        "\n",
        "    for word_dict in word_timestamps:\n",
        "        word_start_ms = int(word_dict[\"start\"] * 1000)\n",
        "        word_end_ms = int(word_dict[\"end\"] * 1000)\n",
        "        word_text = word_dict[\"word\"]\n",
        "\n",
        "        word_position = get_word_timestamp_anchor(\n",
        "            word_start_ms, word_end_ms, word_anchor_option\n",
        "        )\n",
        "\n",
        "        while word_position > float(speaker_end):\n",
        "            turn_index += 1\n",
        "            turn_index = min(turn_index, len(speaker_timestamps) - 1)\n",
        "            speaker_start, speaker_end, speaker = speaker_timestamps[turn_index]\n",
        "\n",
        "            if turn_index == len(speaker_timestamps) - 1:\n",
        "                speaker_end = get_word_timestamp_anchor(\n",
        "                    word_start_ms, word_end_ms, option=\"end\"\n",
        "                )\n",
        "\n",
        "        word_speaker_mapping.append(\n",
        "            {\n",
        "                \"word\": word_text,\n",
        "                \"start_time\": word_start_ms,\n",
        "                \"end_time\": word_end_ms,\n",
        "                \"speaker\": speaker,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return word_speaker_mapping\n",
        "\n",
        "\n",
        "@delayed\n",
        "def read_speaker_timestamps(rttm_file: Path) -> list:\n",
        "    \"\"\"\n",
        "    Read the speaker timestamps from an RTTM file.\n",
        "\n",
        "    Parameters:\n",
        "        rttm_file (Path): The path to the RTTM file.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples containing the start time, end time, and speaker label.\n",
        "    \"\"\"\n",
        "    speaker_timestamps = []\n",
        "    with rttm_file.open(\"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.split(\" \")\n",
        "            start_time = int(float(parts[5]) * 1000)\n",
        "            end_time = start_time + int(float(parts[8]) * 1000)\n",
        "            speaker = int(parts[11].split(\"_\")[-1])\n",
        "            speaker_timestamps.append((start_time, end_time, speaker))\n",
        "    return speaker_timestamps\n",
        "\n",
        "\n",
        "def is_word_sentence_end(x, word_list, sentence_endings):\n",
        "    return x >= 0 and word_list[x][-1] in sentence_endings\n",
        "\n",
        "\n",
        "def get_first_word_idx_of_sentence(\n",
        "    word_idx, word_list, speaker_list, max_words, sentence_endings\n",
        "):\n",
        "    left_idx = word_idx\n",
        "    while (\n",
        "        left_idx > 0\n",
        "        and left_idx - left_idx < max_words\n",
        "        and speaker_list[left_idx - 1] == speaker_list[left_idx]\n",
        "        and not is_word_sentence_end(left_idx - 1, word_list, sentence_endings)\n",
        "    ):\n",
        "        left_idx -= 1\n",
        "\n",
        "    return (\n",
        "        left_idx\n",
        "        if left_idx == 0\n",
        "        or is_word_sentence_end(left_idx - 1, word_list, sentence_endings)\n",
        "        else -1\n",
        "    )\n",
        "\n",
        "\n",
        "def get_last_word_idx_of_sentence(word_idx, word_list, max_words, sentence_endings):\n",
        "    right_idx = word_idx\n",
        "    while (\n",
        "        right_idx < len(word_list)\n",
        "        and right_idx - right_idx < max_words\n",
        "        and not is_word_sentence_end(right_idx, word_list, sentence_endings)\n",
        "    ):\n",
        "        right_idx += 1\n",
        "\n",
        "    return (\n",
        "        right_idx\n",
        "        if right_idx == len(word_list) - 1\n",
        "        or is_word_sentence_end(right_idx, word_list, sentence_endings)\n",
        "        else -1\n",
        "    )\n",
        "\n",
        "\n",
        "def get_realigned_ws_mapping_with_punctuation(\n",
        "    word_speaker_mapping,\n",
        "    max_words_in_sentence=50,\n",
        "    sentence_endings=SENTENCE_ENDING_PUNCTUATIONS,\n",
        "):\n",
        "    wsp_len = len(word_speaker_mapping)\n",
        "\n",
        "    words_list, speaker_list = [], []\n",
        "    for k, line_dict in enumerate(word_speaker_mapping):\n",
        "        word, speaker = line_dict[\"word\"], line_dict[\"speaker\"]\n",
        "        words_list.append(word)\n",
        "        speaker_list.append(speaker)\n",
        "\n",
        "    k = 0\n",
        "    while k < len(word_speaker_mapping):\n",
        "        line_dict = word_speaker_mapping[k]\n",
        "        if (\n",
        "            k < wsp_len - 1\n",
        "            and speaker_list[k] != speaker_list[k + 1]\n",
        "            and not is_word_sentence_end(k, words_list, sentence_endings)\n",
        "        ):\n",
        "            left_idx = get_first_word_idx_of_sentence(\n",
        "                k, words_list, speaker_list, max_words_in_sentence, sentence_endings\n",
        "            )\n",
        "            right_idx = (\n",
        "                get_last_word_idx_of_sentence(\n",
        "                    k,\n",
        "                    words_list,\n",
        "                    max_words_in_sentence - k + left_idx - 1,\n",
        "                    sentence_endings,\n",
        "                )\n",
        "                if left_idx > -1\n",
        "                else -1\n",
        "            )\n",
        "            if min(left_idx, right_idx) == -1:\n",
        "                k += 1\n",
        "                continue\n",
        "\n",
        "            spk_labels = speaker_list[left_idx : right_idx + 1]\n",
        "            mod_speaker = max(set(spk_labels), key=spk_labels.count)\n",
        "            if spk_labels.count(mod_speaker) < len(spk_labels) // 2:\n",
        "                k += 1\n",
        "                continue\n",
        "\n",
        "            speaker_list[left_idx : right_idx + 1] = [mod_speaker] * (\n",
        "                right_idx - left_idx + 1\n",
        "            )\n",
        "            k = right_idx\n",
        "\n",
        "        k += 1\n",
        "\n",
        "    k, realigned_list = 0, []\n",
        "    while k < len(word_speaker_mapping):\n",
        "        line_dict = word_speaker_mapping[k].copy()\n",
        "        line_dict[\"speaker\"] = speaker_list[k]\n",
        "        realigned_list.append(line_dict)\n",
        "        k += 1\n",
        "\n",
        "    return realigned_list\n",
        "\n",
        "\n",
        "def get_sentences_speaker_mapping(\n",
        "    word_speaker_mapping, spk_ts, audio_path\n",
        "):\n",
        "    s, e, spk = spk_ts[0]\n",
        "    prev_spk = spk\n",
        "\n",
        "    mapping = []\n",
        "    sentence_mapping = {\n",
        "        \"speaker\": f\"Speaker {spk}\",\n",
        "        \"start_time\": s,\n",
        "        \"end_time\": e,\n",
        "        \"text\": \"\",\n",
        "        \"audio\": audio_path.name,\n",
        "    }\n",
        "\n",
        "    for wrd_dict in word_speaker_mapping:\n",
        "        wrd, spk = wrd_dict[\"word\"], wrd_dict[\"speaker\"]\n",
        "        s, e = wrd_dict[\"start_time\"], wrd_dict[\"end_time\"]\n",
        "        if spk != prev_spk:\n",
        "            mapping.append(sentence_mapping)\n",
        "            sentence_mapping = {\n",
        "                \"audio\": audio_path.name,\n",
        "                \"speaker\": f\"Speaker {spk}\",\n",
        "                \"start_time\": s,\n",
        "                \"end_time\": e,\n",
        "                \"text\": \"\",\n",
        "            }\n",
        "        else:\n",
        "            sentence_mapping[\"end_time\"] = e\n",
        "        sentence_mapping[\"text\"] += f\"{wrd} \"\n",
        "        prev_spk = spk\n",
        "\n",
        "    mapping.append(sentence_mapping)\n",
        "    return mapping\n",
        "\n",
        "@delayed\n",
        "def process_transcription(\n",
        "    info,\n",
        "    word_speaker_mapping,\n",
        "    speaker_timestamps,\n",
        "    audio_path,\n",
        "    punctuation_model_languages=PUNCTUATION_MODEL_LANGUAGES,\n",
        "):\n",
        "    if info.language in punctuation_model_languages:\n",
        "        # Restoring punctuation in the transcript to help realign the sentences\n",
        "        punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n",
        "        words_list = [x[\"word\"] for x in word_speaker_mapping]\n",
        "        labled_words = punct_model.predict(words_list)\n",
        "\n",
        "        ending_puncts = SENTENCE_ENDING_PUNCTUATIONS\n",
        "        model_puncts = \".,;:!?\"\n",
        "\n",
        "        # We don't want to punctuate U.S.A. with a period. Right?\n",
        "        def is_acronym(x):\n",
        "            return re.fullmatch(\"\\\\b(?:[a-zA-Z]\\\\.){2,}\", x)\n",
        "\n",
        "        for word_dict, labeled_tuple in zip(word_speaker_mapping, labled_words):\n",
        "            word = word_dict[\"word\"]\n",
        "            if (\n",
        "                word\n",
        "                and labeled_tuple[1] in ending_puncts\n",
        "                and (word[-1] not in model_puncts or is_acronym(word))\n",
        "            ):\n",
        "                word += labeled_tuple[1]\n",
        "                if word.endswith(\"..\"):\n",
        "                    word = word.rstrip(\".\")\n",
        "                word_dict[\"word\"] = word\n",
        "\n",
        "        wsm = get_realigned_ws_mapping_with_punctuation(word_speaker_mapping)\n",
        "    else:\n",
        "        print(f\"Punctuation restoration is not available for {info.language} language.\")\n",
        "        wsm = word_speaker_mapping\n",
        "\n",
        "    return get_sentences_speaker_mapping(\n",
        "        wsm, speaker_timestamps, audio_path=audio_path\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173d24a8-4536-4412-88bd-37c784e7cc12",
      "metadata": {
        "id": "173d24a8-4536-4412-88bd-37c784e7cc12",
        "outputId": "3f028594-5d94-490f-b425-08ff90f36c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:29 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2023-09-20 15:02:29 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2023-09-20 15:02:29 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2023-09-20 15:02:29 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2023-09-20 15:02:29 cloud:58] Found existing object /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-09-20 15:02:29 cloud:64] Re-using file from: /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2023-09-20 15:02:29 common:913] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2023-09-20 15:02:29 cloud:58] Found existing object /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-09-20 15:02:29 cloud:64] Re-using file from: /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2023-09-20 15:02:29 cloud:58] Found existing object /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-09-20 15:02:29 cloud:58] Found existing object /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-09-20 15:02:29 common:913] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2023-09-20 15:02:29 cloud:64] Re-using file from: /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2023-09-20 15:02:29 cloud:64] Re-using file from: /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2023-09-20 15:02:29 common:913] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2023-09-20 15:02:29 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:33 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:33 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:33 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:33 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:33 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:33 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:33 features:289] PADDING: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:33 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:33 features:289] PADDING: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:33 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:33 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:33 features:289] PADDING: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:33 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:33 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:33 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:33 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:34 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:34 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:34 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:34 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:37 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-09-20 15:02:37 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-09-20 15:02:37 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:37 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:37 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-09-20 15:02:37 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:37 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-09-20 15:02:37 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:38 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2023-09-20 15:02:38 cloud:58] Found existing object /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2023-09-20 15:02:38 cloud:64] Re-using file from: /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2023-09-20 15:02:38 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:39 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:39 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:39 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:39 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:39 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2023-09-20 15:02:39 cloud:58] Found existing object /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2023-09-20 15:02:39 cloud:64] Re-using file from: /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2023-09-20 15:02:39 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:39 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:39 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:39 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:39 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:39 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2023-09-20 15:02:39 cloud:58] Found existing object /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2023-09-20 15:02:39 cloud:64] Re-using file from: /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2023-09-20 15:02:39 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:39 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:39 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:39 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:39 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:39 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2023-09-20 15:02:39 cloud:58] Found existing object /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2023-09-20 15:02:39 cloud:64] Re-using file from: /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2023-09-20 15:02:39 common:913] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2023-09-20 15:02:39 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:40 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:40 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-09-20 15:02:40 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:40 features:289] PADDING: 16\n",
            "[NeMo I 2023-09-20 15:02:40 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2023-09-20 15:02:40 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2023-09-20 15:02:40 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /home/azureuser/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2023-09-20 15:02:40 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2023-09-20 15:02:40 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false\n",
            "    }\n",
            "[NeMo I 2023-09-20 15:02:40 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2023-09-20 15:02:40 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false\n",
            "    }\n",
            "[NeMo I 2023-09-20 15:02:40 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2023-09-20 15:02:40 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false\n",
            "    }\n",
            "[NeMo I 2023-09-20 15:02:40 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:40 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "splitting manifest:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:40 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2023-09-20 15:02:40 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false\n",
            "    }\n",
            "[NeMo I 2023-09-20 15:02:40 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:40 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "splitting manifest:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:40 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:40 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "splitting manifest:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:40 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:40 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "splitting manifest:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  9.56it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:40 classification_models:272] Perform streaming frame-level VAD\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:40 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2023-09-20 15:02:40 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  2.19it/s]\n",
            "\n",
            "\n",
            "\n",
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  2.97it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  2.49it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:41 classification_models:272] Perform streaming frame-level VAD\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:41 classification_models:272] Perform streaming frame-level VAD\n",
            "[NeMo I 2023-09-20 15:02:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:41 classification_models:272] Perform streaming frame-level VAD\n",
            "[NeMo I 2023-09-20 15:02:41 collections:302] Dataset loaded with 3 items, total duration of  0.04 hours.\n",
            "[NeMo I 2023-09-20 15:02:41 collections:304] # 3 files loaded accounting to # 1 labels\n",
            "[NeMo I 2023-09-20 15:02:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:41 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:41 collections:304] # 2 files loaded accounting to # 1 labels\n",
            "[NeMo I 2023-09-20 15:02:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:41 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:41 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "vad:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "\n",
            "vad:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "vad:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "vad: 100%|| 1/1 [00:00<00:00,  1.38it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:41 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "vad:  67%|   | 2/3 [00:01<00:00,  1.76it/s]it/s]\u001b[A\n",
            "\n",
            "vad:  50%|     | 1/2 [00:01<00:01,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "vad:  50%|     | 1/2 [00:01<00:01,  1.01s/it]\u001b[A\u001b[A\u001b[A\n",
            "generating preds: 100%|| 1/1 [00:00<00:00,  1.27it/s]\u001b[A\n",
            "                                                               \u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:42 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "creating speech segments:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "vad: 100%|| 2/2 [00:01<00:00,  1.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "vad: 100%|| 2/2 [00:01<00:00,  1.47it/s]\u001b[A\u001b[A\u001b[A\n",
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  2.60it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, output/speech-with-music/speaker_outputs/subsegments_scale0.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "vad: 100%|| 2/2 [00:01<00:00,  1.29it/s]\n",
            "vad: 100%|| 3/3 [00:01<00:00,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:42 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "vad: 100%|| 2/2 [00:01<00:00,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:250] Generating predictions with overlapping input segments\n",
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "generating preds:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "generating preds:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "generating preds:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:43 collections:302] Dataset loaded with 7 items, total duration of  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:43 collections:304] # 7 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "[1/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  3.48it/s]\u001b[A\u001b[A\u001b[A\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:389] Saved embedding files to output/speech-with-music/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, output/speech-with-music/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:43 collections:302] Dataset loaded with 8 items, total duration of  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:43 collections:304] # 8 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "[2/5] extract embeddings:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "[2/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  4.26it/s]\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:389] Saved embedding files to output/speech-with-music/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, output/speech-with-music/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:43 collections:302] Dataset loaded with 10 items, total duration of  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:43 collections:304] # 10 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "[3/5] extract embeddings:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "[3/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  6.14it/s]\u001b[A\u001b[A\u001b[A\n",
            "generating preds: 100%|| 1/1 [00:01<00:00,  1.15s/it]\u001b[A\n",
            "                                                               \u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[3/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  3.97it/s]\n",
            "\n",
            "creating speech segments:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:389] Saved embedding files to output/speech-with-music/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, output/speech-with-music/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:44 collections:302] Dataset loaded with 12 items, total duration of  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:44 collections:304] # 12 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "[4/5] extract embeddings:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  6.89it/s]\u001b[A\n",
            "\n",
            "\n",
            "generating preds: 100%|| 1/1 [00:01<00:00,  1.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "                                                               \u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "creating speech segments:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, output/job-interview/speaker_outputs/subsegments_scale0.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "[4/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  5.54it/s]\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:44 collections:302] Dataset loaded with 57 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:44 collections:304] # 57 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[4/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  3.81it/s]\n",
            "\n",
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  4.90it/s]\u001b[A\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:389] Saved embedding files to output/speech-with-music/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, output/speech-with-music/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:44 collections:302] Dataset loaded with 17 items, total duration of  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, output/speech/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2023-09-20 15:02:44 collections:304] # 17 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[5/5] extract embeddings:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:44 collections:302] Dataset loaded with 48 items, total duration of  0.01 hours.\n",
            "[NeMo I 2023-09-20 15:02:44 collections:304] # 48 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "[5/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  3.77it/s]\u001b[A\n",
            "\n",
            "[5/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  2.77it/s]\u001b[A\u001b[A\n",
            "[1/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:389] Saved embedding files to output/speech-with-music/speaker_outputs/embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "clustering:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "\n",
            "[1/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  2.40it/s]\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:389] Saved embedding files to output/job-interview/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, output/job-interview/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:45 collections:302] Dataset loaded with 64 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:45 collections:304] # 64 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[1/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  1.77it/s]\n",
            "                                                               "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "creating speech segments:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:389] Saved embedding files to output/speech/speaker_outputs/embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  2.36it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, output/speech/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  2.31it/s]\n",
            "\n",
            "\n",
            "[2/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  3.49it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:464] Outputs are saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/diffusion/code/Users/yaman/optimization-laion/output/speech-with-music directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:45 collections:302] Dataset loaded with 54 items, total duration of  0.01 hours.\n",
            "[NeMo I 2023-09-20 15:02:45 collections:304] # 54 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  2.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 msdd_models:960] Loading embedding pickle file of scale:0 at output/speech-with-music/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  4.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:45 msdd_models:960] Loading embedding pickle file of scale:1 at output/speech-with-music/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:389] Saved embedding files to output/job-interview/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, output/job-interview/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2023-09-20 15:02:45 msdd_models:960] Loading embedding pickle file of scale:2 at output/speech-with-music/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:45 msdd_models:960] Loading embedding pickle file of scale:3 at output/speech-with-music/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:46 msdd_models:960] Loading embedding pickle file of scale:4 at output/speech-with-music/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:46 msdd_models:938] Loading cluster label file from output/speech-with-music/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, output/devil-wears-prada/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2023-09-20 15:02:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:302] Dataset loaded with 76 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:304] # 76 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[3/5] extract embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:302] Dataset loaded with 68 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:304] # 68 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:46 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "100%|| 1/1 [00:00<00:00, 21.83it/s]1 [00:00<00:00,  1.98it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:46 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2023-09-20 15:02:46 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[3/5] extract embeddings:  50%|     | 1/2 [00:00<00:00,  3.12it/s][NeMo W 2023-09-20 15:02:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  1.70it/s]\n",
            "[NeMo W 2023-09-20 15:02:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[3/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  4.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:389] Saved embedding files to output/speech/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, output/speech/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[NeMo W 2023-09-20 15:02:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:46 msdd_models:1431]   \n",
            "    \n",
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:389] Saved embedding files to output/job-interview/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, output/job-interview/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:302] Dataset loaded with 61 items, total duration of  0.01 hours.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:304] # 61 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[3/5] extract embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:302] Dataset loaded with 98 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:46 collections:304] # 98 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  3.65it/s]\n",
            "\n",
            "[3/5] extract embeddings: 100%|| 1/1 [00:00<00:00,  2.81it/s]\u001b[A\u001b[A\n",
            "[1/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  2.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:389] Saved embedding files to output/speech/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, output/speech/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[4/5] extract embeddings:  50%|     | 1/2 [00:00<00:00,  2.98it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:302] Dataset loaded with 82 items, total duration of  0.01 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:304] # 82 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[4/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  4.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:389] Saved embedding files to output/devil-wears-prada/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, output/devil-wears-prada/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:302] Dataset loaded with 82 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:304] # 82 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[2/5] extract embeddings:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:389] Saved embedding files to output/job-interview/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, output/job-interview/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[4/5] extract embeddings:  50%|     | 1/2 [00:00<00:00,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:302] Dataset loaded with 142 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:304] # 142 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[4/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  4.72it/s]\n",
            "[4/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  3.69it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:389] Saved embedding files to output/speech/speaker_outputs/embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  4.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, output/speech/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "[5/5] extract embeddings:  33%|      | 1/3 [00:00<00:00,  3.27it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:302] Dataset loaded with 120 items, total duration of  0.01 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:304] # 120 files loaded accounting to # 1 labels\n",
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:389] Saved embedding files to output/devil-wears-prada/speaker_outputs/embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[5/5] extract embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, output/devil-wears-prada/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2023-09-20 15:02:47 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:302] Dataset loaded with 95 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:47 collections:304] # 95 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[3/5] extract embeddings:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "[5/5] extract embeddings: 100%|| 3/3 [00:00<00:00,  4.39it/s]\u001b[A\u001b[A\n",
            "[5/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  5.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:48 clustering_diarizer:389] Saved embedding files to output/job-interview/speaker_outputs/embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "clustering:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "[3/5] extract embeddings:  50%|     | 1/2 [00:00<00:00,  2.70it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:48 clustering_diarizer:389] Saved embedding files to output/speech/speaker_outputs/embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[3/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  3.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:48 clustering_diarizer:389] Saved embedding files to output/devil-wears-prada/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:48 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, output/devil-wears-prada/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2023-09-20 15:02:48 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:48 collections:302] Dataset loaded with 124 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:48 collections:304] # 124 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  2.40it/s]\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  2.38it/s]?it/s]\u001b[A\n",
            "\n",
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  2.46it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:48 clustering_diarizer:464] Outputs are saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/diffusion/code/Users/yaman/optimization-laion/output/job-interview directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[NeMo W 2023-09-20 15:02:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:0 at output/job-interview/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:1 at output/job-interview/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 clustering_diarizer:464] Outputs are saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/diffusion/code/Users/yaman/optimization-laion/output/speech directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:0 at output/speech/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:2 at output/job-interview/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:1 at output/speech/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:3 at output/job-interview/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:2 at output/speech/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:4 at output/job-interview/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:938] Loading cluster label file from output/job-interview/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:3 at output/speech/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:960] Loading embedding pickle file of scale:4 at output/speech/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:48 msdd_models:938] Loading cluster label file from output/speech/speaker_outputs/subsegments_scale4_cluster.label\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[4/5] extract embeddings:  50%|     | 1/2 [00:00<00:00,  3.11it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2023-09-20 15:02:49 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2023-09-20 15:02:49 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|| 1/1 [00:00<00:00, 48.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2023-09-20 15:02:49 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 1/1 [00:00<00:00, 25.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2023-09-20 15:02:49 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  4.33it/s]\n",
            "[NeMo W 2023-09-20 15:02:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:49 clustering_diarizer:389] Saved embedding files to output/devil-wears-prada/speaker_outputs/embeddings\n",
            "[NeMo I 2023-09-20 15:02:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, output/devil-wears-prada/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-09-20 15:02:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-09-20 15:02:49 collections:302] Dataset loaded with 190 items, total duration of  0.02 hours.\n",
            "[NeMo I 2023-09-20 15:02:49 collections:304] # 190 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[5/5] extract embeddings:   0%|          | 0/3 [00:00<?, ?it/s][NeMo W 2023-09-20 15:02:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 msdd_models:1431]   \n",
            "    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 msdd_models:1431]   \n",
            "    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[5/5] extract embeddings: 100%|| 3/3 [00:00<00:00,  6.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:49 clustering_diarizer:389] Saved embedding files to output/devil-wears-prada/speaker_outputs/embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  4.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:50 clustering_diarizer:464] Outputs are saved in /mnt/batch/tasks/shared/LS_root/mounts/clusters/diffusion/code/Users/yaman/optimization-laion/output/devil-wears-prada directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[NeMo W 2023-09-20 15:02:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:50 msdd_models:960] Loading embedding pickle file of scale:0 at output/devil-wears-prada/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:50 msdd_models:960] Loading embedding pickle file of scale:1 at output/devil-wears-prada/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:50 msdd_models:960] Loading embedding pickle file of scale:2 at output/devil-wears-prada/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:50 msdd_models:960] Loading embedding pickle file of scale:3 at output/devil-wears-prada/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:50 msdd_models:960] Loading embedding pickle file of scale:4 at output/devil-wears-prada/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2023-09-20 15:02:50 msdd_models:938] Loading cluster label file from output/devil-wears-prada/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2023-09-20 15:02:50 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2023-09-20 15:02:50 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1/1 [00:00<00:00, 41.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:50 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2023-09-20 15:02:50 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-09-20 15:02:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[NeMo W 2023-09-20 15:02:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-09-20 15:02:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-09-20 15:02:50 msdd_models:1431]   \n",
            "    \n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# 1. Convert audios to WAV format\n",
        "sequence_bag = bag.from_sequence(audio_dir.iterdir())\n",
        "converted_audio_paths = sequence_bag.map(convert_audio_to_wav).compute()\n",
        "\n",
        "# Create a new bag from the converted audio paths for further processing\n",
        "converted_audio_bag = bag.from_sequence(converted_audio_paths)\n",
        "\n",
        "# 2. Parallel execution of Whisper transcription, align_bag, and creation of nemo_configs\n",
        "whisper_transcriptions_bag = converted_audio_bag.map(get_whisper_transcription)\n",
        "\n",
        "# Unpack the results from `get_whisper_transcription`\n",
        "whisper_results_bag = whisper_transcriptions_bag.map(lambda x: x[0])\n",
        "info_bag = whisper_transcriptions_bag.map(lambda x: x[1])\n",
        "\n",
        "# Align Transcriptions\n",
        "align_bag = bag.map(align_transcription, converted_audio_bag, whisper_results_bag, info_bag)\n",
        "\n",
        "# Nemo Configs\n",
        "nemo_configs_bag = converted_audio_bag.map(create_nemo_diarization_config, nemo_config_path=NEMO_DIARIZATION_CONFIG)\n",
        "\n",
        "# Compute all results in parallel\n",
        "whisper_transcriptions, aligned_results, nemo_configs = compute(whisper_transcriptions_bag, align_bag, nemo_configs_bag)\n",
        "\n",
        "# 3. NeMo diarization\n",
        "# for audio, config in zip(converted_audio_paths, nemo_configs):\n",
        "#     get_nemo_diarization(audio, config)\n",
        "\n",
        "# Todo: Optimize Performance or add batch processing\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def diarize_wrapper(args):\n",
        "    audio_path, nemo_config = args\n",
        "    return get_nemo_diarization(audio_path, nemo_config)\n",
        "\n",
        "# Set a suitable number for max_workers based on your machine's capabilities\n",
        "# A good starting point might be the number of CPU cores available.\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    results = list(executor.map(diarize_wrapper, zip(converted_audio_paths, nemo_configs)))\n",
        "# Todo: end\n",
        "\n",
        "# 4. Generate RTTM file paths\n",
        "rttm_file_paths = [OUTPUT_PATH / audio_path.stem /\"pred_rttms\" / f\"{audio_path.stem}.rttm\" for audio_path in converted_audio_paths]\n",
        "\n",
        "# 5. Parallel execution of the remaining tasks\n",
        "speaker_timestamps_tasks = [read_speaker_timestamps(path) for path in rttm_file_paths]\n",
        "speaker_timestamps = compute(*speaker_timestamps_tasks)\n",
        "\n",
        "map_words_tasks = [map_words_to_speaker(aligned, speaker) for aligned, speaker in zip(aligned_results, speaker_timestamps)]\n",
        "mapped_words = compute(*map_words_tasks)\n",
        "\n",
        "processed_audio_data_tasks = [process_transcription(info, map_word, speaker, audio)\n",
        "                              for info, map_word, speaker, audio in zip(info_bag, mapped_words, speaker_timestamps, converted_audio_paths)]\n",
        "\n",
        "processed_data = compute(*processed_audio_data_tasks)\n",
        "\n",
        "# Create a Dataframe\n",
        "df = pd.concat([pd.DataFrame(item) for item in processed_data], ignore_index=True)\n",
        "\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "207fdb43-2393-418f-b56c-1d27da411841",
      "metadata": {
        "id": "207fdb43-2393-418f-b56c-1d27da411841",
        "outputId": "58411b16-226e-403e-b6f2-b4dfb2af5792"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43.36835193634033"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "134df497-0aab-4fa1-9d95-31a45b36b9a4",
      "metadata": {
        "id": "134df497-0aab-4fa1-9d95-31a45b36b9a4",
        "outputId": "79c6c695-23f7-4c83-85d5-388613b2cf86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>text</th>\n",
              "      <th>audio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Speaker 2</td>\n",
              "      <td>7020</td>\n",
              "      <td>7000</td>\n",
              "      <td>Who are you?</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>8523</td>\n",
              "      <td>13360</td>\n",
              "      <td>My name is Andy Sachs. I recently graduated fr...</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Speaker 2</td>\n",
              "      <td>13740</td>\n",
              "      <td>14633</td>\n",
              "      <td>What are you doing here?</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>16601</td>\n",
              "      <td>36600</td>\n",
              "      <td>Well, I think I could do a good job as your as...</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Speaker 2</td>\n",
              "      <td>37320</td>\n",
              "      <td>38299</td>\n",
              "      <td>So you don't read runway?</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>40911</td>\n",
              "      <td>41035</td>\n",
              "      <td>No.</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Speaker 2</td>\n",
              "      <td>41600</td>\n",
              "      <td>43271</td>\n",
              "      <td>And before today you had never heard of me?</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>46760</td>\n",
              "      <td>46887</td>\n",
              "      <td>No.</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Speaker 2</td>\n",
              "      <td>47560</td>\n",
              "      <td>50119</td>\n",
              "      <td>And you have no style or some sort of fashion?</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>53806</td>\n",
              "      <td>55917</td>\n",
              "      <td>Well, I think that depends on what you're...</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Speaker 2</td>\n",
              "      <td>57645</td>\n",
              "      <td>58454</td>\n",
              "      <td>What was a new question?</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>62583</td>\n",
              "      <td>95558</td>\n",
              "      <td>I was editor in Chief of the Daily Northwester...</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>95740</td>\n",
              "      <td>104318</td>\n",
              "      <td>I've got the exclusive on the Cavali Faguina. ...</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>105361</td>\n",
              "      <td>107198</td>\n",
              "      <td>Thank you, or your time.</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>109261</td>\n",
              "      <td>132521</td>\n",
              "      <td>Is that sad little person? Are we doing it bef...</td>\n",
              "      <td>devil-wears-prada.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>1660</td>\n",
              "      <td>1800</td>\n",
              "      <td></td>\n",
              "      <td>job-interview.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>1721</td>\n",
              "      <td>7698</td>\n",
              "      <td>Best experience in all aspects of video produc...</td>\n",
              "      <td>job-interview.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>8160</td>\n",
              "      <td>12297</td>\n",
              "      <td>Well, sir, for the past seven years, I've been...</td>\n",
              "      <td>job-interview.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>13780</td>\n",
              "      <td>14055</td>\n",
              "      <td>YouTube?</td>\n",
              "      <td>job-interview.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>14820</td>\n",
              "      <td>51112</td>\n",
              "      <td>Yes, sir. I think that YouTube is the perfect ...</td>\n",
              "      <td>job-interview.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>53684</td>\n",
              "      <td>54780</td>\n",
              "      <td>What could be more important?</td>\n",
              "      <td>job-interview.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>56060</td>\n",
              "      <td>63617</td>\n",
              "      <td>Thank you, sir. That's what I'm saying. I'm so...</td>\n",
              "      <td>job-interview.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>64721</td>\n",
              "      <td>68037</td>\n",
              "      <td>I was showing you the door, Mr. Davis. That's ...</td>\n",
              "      <td>job-interview.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>300</td>\n",
              "      <td>26515</td>\n",
              "      <td>One day of drumming, one week of drumming, one...</td>\n",
              "      <td>speech-with-music.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Speaker 0</td>\n",
              "      <td>3180</td>\n",
              "      <td>85279</td>\n",
              "      <td>I was born a dragonstone. Not that I can remem...</td>\n",
              "      <td>speech.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      speaker  start_time  end_time  \\\n",
              "0   Speaker 2        7020      7000   \n",
              "1   Speaker 0        8523     13360   \n",
              "2   Speaker 2       13740     14633   \n",
              "3   Speaker 0       16601     36600   \n",
              "4   Speaker 2       37320     38299   \n",
              "5   Speaker 0       40911     41035   \n",
              "6   Speaker 2       41600     43271   \n",
              "7   Speaker 0       46760     46887   \n",
              "8   Speaker 2       47560     50119   \n",
              "9   Speaker 0       53806     55917   \n",
              "10  Speaker 2       57645     58454   \n",
              "11  Speaker 0       62583     95558   \n",
              "12  Speaker 1       95740    104318   \n",
              "13  Speaker 0      105361    107198   \n",
              "14  Speaker 1      109261    132521   \n",
              "15  Speaker 0        1660      1800   \n",
              "16  Speaker 1        1721      7698   \n",
              "17  Speaker 0        8160     12297   \n",
              "18  Speaker 1       13780     14055   \n",
              "19  Speaker 0       14820     51112   \n",
              "20  Speaker 1       53684     54780   \n",
              "21  Speaker 0       56060     63617   \n",
              "22  Speaker 1       64721     68037   \n",
              "23  Speaker 0         300     26515   \n",
              "24  Speaker 0        3180     85279   \n",
              "\n",
              "                                                 text                  audio  \n",
              "0                                       Who are you?   devil-wears-prada.wav  \n",
              "1   My name is Andy Sachs. I recently graduated fr...  devil-wears-prada.wav  \n",
              "2                           What are you doing here?   devil-wears-prada.wav  \n",
              "3   Well, I think I could do a good job as your as...  devil-wears-prada.wav  \n",
              "4                          So you don't read runway?   devil-wears-prada.wav  \n",
              "5                                                No.   devil-wears-prada.wav  \n",
              "6        And before today you had never heard of me?   devil-wears-prada.wav  \n",
              "7                                                No.   devil-wears-prada.wav  \n",
              "8     And you have no style or some sort of fashion?   devil-wears-prada.wav  \n",
              "9       Well, I think that depends on what you're...   devil-wears-prada.wav  \n",
              "10                          What was a new question?   devil-wears-prada.wav  \n",
              "11  I was editor in Chief of the Daily Northwester...  devil-wears-prada.wav  \n",
              "12  I've got the exclusive on the Cavali Faguina. ...  devil-wears-prada.wav  \n",
              "13                          Thank you, or your time.   devil-wears-prada.wav  \n",
              "14  Is that sad little person? Are we doing it bef...  devil-wears-prada.wav  \n",
              "15                                                         job-interview.wav  \n",
              "16  Best experience in all aspects of video produc...      job-interview.wav  \n",
              "17  Well, sir, for the past seven years, I've been...      job-interview.wav  \n",
              "18                                          YouTube?       job-interview.wav  \n",
              "19  Yes, sir. I think that YouTube is the perfect ...      job-interview.wav  \n",
              "20                     What could be more important?       job-interview.wav  \n",
              "21  Thank you, sir. That's what I'm saying. I'm so...      job-interview.wav  \n",
              "22  I was showing you the door, Mr. Davis. That's ...      job-interview.wav  \n",
              "23  One day of drumming, one week of drumming, one...  speech-with-music.wav  \n",
              "24  I was born a dragonstone. Not that I can remem...             speech.wav  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f73087e-831b-4d57-bd3a-af62c11ccc38",
      "metadata": {
        "id": "2f73087e-831b-4d57-bd3a-af62c11ccc38"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "laion",
      "language": "python",
      "name": "laion"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}